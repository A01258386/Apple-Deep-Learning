# -*- coding: utf-8 -*-
"""Apple -Stacked LSTM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1H-jpm_x1xsx0hYLIKA_A_Nq3cQv6tixH
"""

###Data Collection
import pandas_datareader as pdr

df = pdr.get_data_tiingo('AAPL',api_key = 'f289314a30b5088e69d5b2a0644b2eabd85afd21')

df.to_csv('AAPL.csv')

import pandas as pd

df=pd.read_csv('AAPL.csv')

df.tail()

df1=df.reset_index()['close']

df1.shape

df1

import matplotlib.pyplot as plt
plt.plot(df1)

###LSTM i sensetive to the scale of the data, so MinMax

import numpy as np
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler(feature_range=(0,1))
df1 =scaler.fit_transform(np.array(df1).reshape(-1,1))

df1.shape

print(df1)

###splitting dataset into train and test split
training_size = int(len(df1)*0.65)
test_size =len(df1)-training_size
train_data,test_data = df1[0:training_size,:],df1[training_size:len(df1),:1]

training_size,test_size
train_data

import numpy#convert an array of values into a dataset matrix
def create_dataset(dataset,time_step=1): #time_step=1 Features from previous 
  dataX,dataY = [],[]
  for i in range(len(dataset)-time_step-1):
    a = dataset[i:(i+time_step),0]
    dataX.append(a)
    dataY.append(dataset[i+time_step,0])
  return numpy.array(dataX),numpy.array(dataY)

#reshape into X=t,t+1,t+2,t+3, and Y=t+4
time_step = 100
X_train,y_train =create_dataset(train_data,time_step)
X_test,ytest = create_dataset(test_data,time_step)

print(X_train)

print(X_test.shape),print(ytest.shape)

#reshape input to be [samples, time steps, feature] which is required for LSTM
X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)
X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)

